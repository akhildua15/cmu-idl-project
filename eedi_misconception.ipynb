{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSZWfaA9kytu",
        "outputId": "002321d2-42dd-4492-c6a7-ea8774463962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 25 17:06:02 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # Run this to see what GPU you have"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet # Install WandB"
      ],
      "metadata": {
        "id": "TMmI6RSomxtU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Use the same Kaggle code from HW1P2\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"jdrhgojdrhg\",\"key\":\"e3737073b469c90b4b90bd44e179b412\"}')\n",
        "    # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eNiDSCsnEPY",
        "outputId": "736a825a-c292-4ccf-f2cf-58c8bf8981bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m51.2/59.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73248 sha256=b8f85c64449f78d1046dc9a053664177e29699ea37270978db7377ddb37c814e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/76/ca/e58f8afa83166a0e68f0d5cd2e7f99d260bdc40e35da080eee\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.6.17\n",
            "    Uninstalling kaggle-1.6.17:\n",
            "      Successfully uninstalled kaggle-1.6.17\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics as mt\n",
        "from scipy.optimize import brentq\n",
        "from scipy.interpolate import interp1d\n",
        "import glob\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from torch.utils.data import default_collate\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uvESdgcohQa",
        "outputId": "f7da15d8-a612-41b2-b8ce-75f16ed25b41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/data'\n",
        "\n",
        "!kaggle competitions download -c eedi-mining-misconceptions-in-mathematics\n",
        "!unzip -qo 'eedi-mining-misconceptions-in-mathematics.zip' -d '/content/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "micxvpxIotsV",
        "outputId": "1a4a7354-0e53-4a5d-fdda-d4133c522ac5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading eedi-mining-misconceptions-in-mathematics.zip to /content\n",
            "\r  0% 0.00/260k [00:00<?, ?B/s]\n",
            "\r100% 260k/260k [00:00<00:00, 74.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "qZm4EfkfoOq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'batch_size': 64,\n",
        "    'epochs': 20,\n",
        "    'data_dir': \"/content/data/eedi-mining-misconceptions-in-mathematics/\n",
        "    'checkpoint_dir': \"/content/checkpoints\", #TODO\n",
        "    # Include other parameters as needed.\n",
        "}"
      ],
      "metadata": {
        "id": "gIdF3rtQoTh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "k3_Ko6fSpXpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, csv_file, transform):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dJfuB89NpY0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestQuestionDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, csv_file, transform):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      pass"
      ],
      "metadata": {
        "id": "R2BcDZSJpel-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}